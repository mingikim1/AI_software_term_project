{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingikim1/AI_software_term_project/blob/main/TermprojectB_201901001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMeEpJHm0tQJ"
      },
      "source": [
        "Q/A system 코드를 하단에 자유롭게 작성해주세요\n",
        "\n",
        "TA는 하단 코드 실행 후\n",
        "\n",
        "./release 폴더 하단에 생성된 파일을 기준으로 평가를 진행합니다\n",
        "파일명은 {본인학번}.test.json으로 저장\n",
        "\n",
        "===================== 필수 ===============================\n",
        "\n",
        "1. ./data/test.json 파일 기준으로 코드 변경\n",
        "  \n",
        "  현재는 테스트용 valid.json 이 제공되었지만 test.json 으로 실행 될 수 있도록 코드 수정\n",
        "\n",
        "2. test.json 형식 확인\n",
        "\n",
        "  { question : 질문 내용, answer : 정답 }\n",
        "\n",
        "3. 결과 파일 명은 {학번}.test.json 으로 통일\n",
        "  \n",
        "  파일은 ./realease 폴더 아래 위치\n",
        "\n",
        "  예시) ./release/{학번}.test.json\n",
        "\n",
        "4. 반드시 실행 여부 테스트 후에 제출, 실행 안 될 시 점수 x  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zyY-BUiad8G"
      },
      "outputs": [],
      "source": [
        "!mkdir data release llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m2GUczOfarx2",
        "outputId": "321552a4-c190-4d07-e98e-a070dbae952a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-20 13:15:42--  https://drive.google.com/uc?id=1ZERESR4o7Wcx7J1GsHZX9dAjPSilvmgQ&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.175.102, 142.251.175.139, 142.251.175.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.175.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1ZERESR4o7Wcx7J1GsHZX9dAjPSilvmgQ&export=download [following]\n",
            "--2024-12-20 13:15:42--  https://drive.usercontent.google.com/download?id=1ZERESR4o7Wcx7J1GsHZX9dAjPSilvmgQ&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.175.132, 2404:6800:4003:c1c::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.175.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1011 [application/octet-stream]\n",
            "Saving to: ‘./data/test.json’\n",
            "\n",
            "./data/test.json    100%[===================>]    1011  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-20 13:15:45 (52.2 MB/s) - ‘./data/test.json’ saved [1011/1011]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# test.json으로 바꿈, 경로만 변경 필요\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?id=1ZERESR4o7Wcx7J1GsHZX9dAjPSilvmgQ&export=download' -O ./data/test.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "file_id = \"1CEuxDQakOvBSb4Xqy1d-aFZDK1GiYrdo\"\n",
        "\n",
        "# ZIP 파일을 다운로드할 경로\n",
        "zip_file_path = '/content/pdf.zip'\n",
        "\n",
        "# ZIP 파일 다운로드\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', zip_file_path, quiet=False)\n",
        "\n",
        "# 압축을 풀 폴더 경로\n",
        "unzip_dir = '/content/'\n",
        "\n",
        "# 압축 풀기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J12_qtfKxear",
        "outputId": "c07a285d-49a8-4bc5-ac42-db36c4bd1fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1CEuxDQakOvBSb4Xqy1d-aFZDK1GiYrdo\n",
            "From (redirected): https://drive.google.com/uc?id=1CEuxDQakOvBSb4Xqy1d-aFZDK1GiYrdo&confirm=t&uuid=ffc9f253-a164-4a88-82ca-66cefabdce78\n",
            "To: /content/pdf.zip\n",
            "100%|██████████| 84.5M/84.5M [00:00<00:00, 93.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FFVw3S89c5Oh",
        "outputId": "c8e9591e-2bf0-44dc-a53b-91833c0a5e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.0\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate bitsandbytes transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eYXhMljHF6t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvlxnB_bk-r_"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1GD1Kmbzu43VoWVJOPgdyDK2UzsEUnnWY\"\n",
        "\n",
        "# ZIP 파일을 다운로드할 경로\n",
        "zip_file_path = '/content/llm.zip'\n",
        "\n",
        "# ZIP 파일 다운로드\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_file_path, quiet=False)\n",
        "\n",
        "# 압축을 풀 폴더 경로\n",
        "unzip_dir = '/content/llm'\n",
        "\n",
        "# 압축 풀기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)"
      ],
      "metadata": {
        "id": "kYNy8E9qTGvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z6wmQWZvHAlu"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"/content/llm\",\n",
        "    torch_dtype=torch.bfloat16,  # bfloat16\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/llm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Jw63Vek6pk"
      },
      "source": [
        "## PDF Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xLWluCvYWkdL"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U4V2VaVtnU2c"
      },
      "outputs": [],
      "source": [
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dH47KtI7zchb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain.document_loaders import PDFMinerLoader\n",
        "\n",
        "# 1. PDF에서 텍스트 로드\n",
        "def load_pdf_text(pdf_path):\n",
        "    loader = PDFMinerLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "    # 모든 페이지의 텍스트를 하나로 결합\n",
        "    text = \" \".join([doc.page_content for doc in docs])\n",
        "    return text\n",
        "\n",
        "# 2. 불필요한 헤더 제거\n",
        "def remove_header(text):\n",
        "    header_pattern = r'^Open in app\\n\\nSearch\\n\\n.*?More\\n\\n'  # 헤더 패턴\n",
        "    cleaned_text = re.sub(header_pattern, '', text, flags=re.DOTALL)  # 헤더 제거\n",
        "    return cleaned_text\n",
        "\n",
        "# 3. 페이지 구분 문자 수정\n",
        "def modify_page_breaks(text):\n",
        "    # 페이지 구분자 \\n\\n\\x0c를 \\n\\n로 바꾸기\n",
        "    text = re.sub(r'\\n\\n\\x0c', '\\n\\n', text)  # 페이지 구분자 수정\n",
        "    return text\n",
        "\n",
        "# 4. 문장 중간의 개행 제거\n",
        "def remove_mid_sentence_newlines(text):\n",
        "    # 문장 중간의 개행 제거 (문장 끝은 제외)\n",
        "    text = re.sub(r'(?<=\\w)\\n+(?=\\w)', ' ', text)  # 단어 사이의 \\n을 공백으로 대체\n",
        "    return text\n",
        "\n",
        "# 5. 문장 사이에 있는 불필요한 \\n\\n 제거\n",
        "def remove_unwanted_newlines(text):\n",
        "    # 문장 사이의 불필요한 \\n\\n을 공백으로 대체\n",
        "    text = re.sub(r'(?<=\\w)\\n\\n(?=\\w)', ' ', text)  # 문장 사이의 \\n\\n을 공백으로 대체\n",
        "    return text\n",
        "\n",
        "# 6. 콤마 뒤의 불필요한 \\n\\n 제거\n",
        "def remove_newlines_after_comma(text):\n",
        "    # 콤마 뒤에 있는 \\n\\n을 공백으로 대체\n",
        "    text = re.sub(r',\\n+', ', ', text)  # 콤마 뒤에 오는 \\n을 공백으로 대체\n",
        "    return text\n",
        "\n",
        "# 7. 마침표 앞의 \\n\\n 제거\n",
        "def remove_newlines_before_period(text):\n",
        "    # 문장 끝의 마침표 앞에 있는 \\n\\n을 공백으로 대체\n",
        "    text = re.sub(r'\\n\\n(?=\\.)', ' ', text)  # 마침표 앞의 \\n\\n을 공백으로 대체\n",
        "    return text\n",
        "\n",
        "\n",
        "# 8. \\n\\n으로 구분된 부분 확인\n",
        "def find_newline_separated_blocks(text):\n",
        "    # \\n\\n으로 구분된 부분 찾기\n",
        "    blocks = re.split(r'\\n\\n', text)\n",
        "    return blocks\n",
        "\n",
        "def create_overlapping_blocks(blocks, block_size=5, overlap_size=2):\n",
        "    overlapping_blocks = []\n",
        "\n",
        "    # Start creating overlapping blocks\n",
        "    for i in range(0, len(blocks), block_size - overlap_size):\n",
        "        # Extract a block of the specified size\n",
        "        block = blocks[i:i + block_size]\n",
        "\n",
        "        # Join the blocks into one chunk of text\n",
        "        overlapping_blocks.append(\" \".join(block))\n",
        "\n",
        "    return overlapping_blocks\n",
        "\n",
        "all_text = []\n",
        "\n",
        "for i in range(1, 52):\n",
        "  pdf_path = f'/content/pdf/hugman_2024_ML_book-{i}.pdf'\n",
        "  text = load_pdf_text(pdf_path)\n",
        "\n",
        "  # PDF 텍스트 로드\n",
        "  text = load_pdf_text(pdf_path)\n",
        "\n",
        "  # 헤더 제거\n",
        "  cleaned_text = remove_header(text)\n",
        "\n",
        "  # 페이지 구분자 수정\n",
        "  cleaned_text = modify_page_breaks(cleaned_text)\n",
        "\n",
        "  # 문장 중간의 개행 제거\n",
        "  cleaned_text = remove_mid_sentence_newlines(cleaned_text)\n",
        "\n",
        "  # 문장 사이의 불필요한 \\n\\n 제거\n",
        "  cleaned_text = remove_unwanted_newlines(cleaned_text)\n",
        "\n",
        "  # 콤마 뒤의 불필요한 \\n\\n 제거\n",
        "  cleaned_text = remove_newlines_after_comma(cleaned_text)\n",
        "\n",
        "  # 마침표 앞의 \\n\\n 제거\n",
        "  cleaned_text = remove_newlines_before_period(cleaned_text)\n",
        "\n",
        "  # \\n\\n으로 구분된 부분 찾기\n",
        "  blocks = find_newline_separated_blocks(cleaned_text)\n",
        "\n",
        "  overlapping_blocks = create_overlapping_blocks(blocks)\n",
        "\n",
        "  all_text.extend(overlapping_blocks)\n",
        "  print(\"Rate: {}/51\".format(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDCMoassBk3j"
      },
      "source": [
        "## Text Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pPdHxqIKB-Rf"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1Z5TpgJ_Q0tfQywU4aI4wvpJsnmAWCsss\"\n",
        "\n",
        "# ZIP 파일을 다운로드할 경로\n",
        "zip_file_path = '/content/embedding.zip'\n",
        "\n",
        "# ZIP 파일 다운로드\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', zip_file_path, quiet=False)\n",
        "\n",
        "# 압축을 풀 폴더 경로\n",
        "unzip_dir = '/content/'\n",
        "\n",
        "# 압축 풀기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)"
      ],
      "metadata": {
        "id": "A0Lg_nMUURyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C95N6_k2H72y"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"/content/embedding\",\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob2oD_yfJAXc"
      },
      "source": [
        "## FAISS DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T_U10JmOIpe9"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-ghBseYJVWW"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkWOWgxTMnuP"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "# overlapping_blocks를 Document 객체로 변환\n",
        "documents = [Document(page_content=block) for block in all_text]\n",
        "\n",
        "# FAISS VectorStore 생성\n",
        "vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynkJuLzcNVO6"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gCU_66NhYs"
      },
      "source": [
        "## Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y2CaC5AFOSbT"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jlUC1SjNi1i"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"#Instruct:\n",
        "       Answer the question related to artificial intelligence knowledge.\n",
        "       Use the PDF context as a helpful reference to extract relevant information, but ensure your answer integrates a balanced understanding of both the provided context and your general knowledge.\n",
        "       Avoid over-reliance on the context if it does not fully address the question.\n",
        "       Your answer should be strictly focused on addressing the question directly, providing the most relevant and complete response possible.\n",
        "       Ensure your response is detailed enough to provide clarity, yet concise and free of unnecessary elaborations.\n",
        "       Write in a natural, conversational tone while maintaining the technical accuracy required for the topic.\n",
        "       **Do not include any extra sections, tags, or annotations** like #Explanation, #References, #Note, or any other similar labels.\n",
        "       Provide only the final answer in a clean and natural sentence.\n",
        "\n",
        "       #Question:\n",
        "       {question}\n",
        "\n",
        "       #Context:\n",
        "       {context}\n",
        "\n",
        "       #Answer:\"\"\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTY0zmbeQEXw"
      },
      "source": [
        "## Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9qNhGSWTSkC"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from transformers import pipeline\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.schema.runnable import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px2IX60MTPsf"
      },
      "outputs": [],
      "source": [
        "text_generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dZaZ4M5fTdzj"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ9uE9F4TsAI"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just checking\n",
        "response = chain.invoke(\"What is transformer?\")\n",
        "clean_response = response.split(\"#Answer:\")[-1].strip()\n",
        "clean_response"
      ],
      "metadata": {
        "id": "9PaDuvhs_O4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrKh5DWbslIj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# valid.json 파일 열기\n",
        "with open(\"/content/data/test.json\", \"r\") as file:\n",
        "    questions = json.load(file)\n",
        "\n",
        "# 답변 생성 및 저장\n",
        "output = []\n",
        "for entry in questions:\n",
        "    question = entry[\"question\"]\n",
        "    # 질문을 처리하고 답변 생성\n",
        "    response = chain.invoke(question)\n",
        "    clean_response = response.split(\"#Answer:\")[-1].strip()  # #Answer 뒤의 내용만 추출\n",
        "    # 결과 저장\n",
        "    output.append({\n",
        "        \"question\": question,\n",
        "        \"answer\": clean_response\n",
        "    })\n",
        "\n",
        "# 결과 JSON 파일 저장\n",
        "with open(\"/content/release/201901001.test.json\", \"w\") as file:\n",
        "    json.dump(output, file, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}